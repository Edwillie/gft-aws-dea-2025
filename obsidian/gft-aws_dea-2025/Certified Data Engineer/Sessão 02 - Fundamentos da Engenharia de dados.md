# Tipos de dados (Estruturados, Semi Estruturados, N√£o Estruturados)
## ‚úÖ Tipos de Dados: Conceitos Fundamentais
A categoriza√ß√£o dos dados em tr√™s tipos principais √© essencial para entender como armazen√°-los, process√°-los e analis√°-los:
### 1. *Dados Estruturados*
- **Defini√ß√£o:** Dados organizados em esquemas fixos (linhas e colunas), normalmente encontrados em bancos de dados relacionais.    
- **Caracter√≠sticas:**    
    - Estrutura r√≠gida e conhecida.        
    - Facilmente consult√°vel via SQL.        
    - Colunas com tipos de dados definidos.        
- **Exemplos:**    
    - Bancos de dados como **PostgreSQL, MySQL, Oracle, Redshift**.        
    - Arquivos **CSV** (desde que bem formados).        
    - Planilhas do **Excel** com estrutura coerente.     
### 2. *Dados N√£o Estruturados*
- **Defini√ß√£o:** Dados sem esquema predefinido, dif√≠ceis de consultar diretamente.    
- **Caracter√≠sticas:**    
    - Necessitam pr√©-processamento e extra√ß√£o de metadados.        
    - N√£o h√° formato tabular ou de colunas fixas.        
- **Exemplos:**    
    - Arquivos de **√°udio, v√≠deo, imagem**.        
    - **Textos livres**, como artigos, livros, postagens.        
    - **E-mails** (especialmente corpo do e-mail).        
    - **PDFs escaneados**, grava√ß√µes de chamadas, etc.        
<div style="page-break-after: always;"></div>
### 3. *Dados Semiestruturados*

- **Defini√ß√£o:** Dados com alguma organiza√ß√£o interna (tags, delimitadores, etc.), mas n√£o em formato relacional tradicional.    
- **Caracter√≠sticas:**    
    - Possuem estrutura parcial, normalmente hier√°rquica.        
    - Permitem extra√ß√£o de schema de forma din√¢mica (schema-on-read).        
    - S√£o comuns em pipelines de dados modernos.        
- **Exemplos:**    
    - Arquivos **JSON, XML**.        
    - **Logs de servidores** (Apache, CloudWatch, etc.).        
    - **Cabe√ßalhos de e-mails**.        
    - Arquivos **YAML**, **Avro**, **Parquet** (quando usados sem schema expl√≠cito no cat√°logo).        

---
## üîç Complementos e Melhorias Sugeridas
### *Tipos de dados modernos utilizados em Engenharia de Dados:*
- **Avro, Parquet, ORC**:    
    - Embora sejam formatos bin√°rios, s√£o considerados **semiestruturados** quando schema √© lido dinamicamente.        
    - Suportam compress√£o e colunas com diferentes tipos.        
    - Muito utilizados em data lakes (S3 + Glue + Athena).        
### *Schema-on-Read vs. Schema-on-Write*:
- **Schema-on-Write:** Obrigat√≥rio para dados estruturados (ex: banco relacional).    
- **Schema-on-Read:** Comum para dados semiestruturados em data lakes (ex: arquivos JSON lidos pelo Athena).    
### *Ferramentas para manipula√ß√£o de tipos de dados:*
- **AWS Glue DataBrew, Glue Schema Registry, Amazon Macie** para tipos sens√≠veis e classifica√ß√£o.    
- **OpenSearch** para dados semiestruturados com consultas full-text.    
- **Tesseract OCR** para extrair texto de PDFs/imagens (transformando n√£o estruturado em estruturado).    
<div style="page-break-after: always;"></div>
### *Casos de uso reais:*
- **Pipeline de logs (semiestruturado)**: leitura de arquivos no S3 ‚Üí transforma√ß√£o com PySpark ‚Üí ingest√£o no Redshift.    
- **Treinamento de IA (n√£o estruturado)**: extra√ß√£o de √°udio/imagem para entrada em modelos de ML.
# Caracter√≠sticas dos dados (os V's)
### üìå Resumo dos 3 V's do Big Data
#### 1. *Volume*
Refere-se √† **quantidade total de dados** gerados e armazenados. Pode variar de gigabytes at√© petabytes ou mais.
- **Impacto:** influencia o modelo de armazenamento, processamento e transporte dos dados.    
- **Exemplos:**    
    - M√≠dias sociais gerando terabytes di√°rios com postagens, v√≠deos e imagens.        
    - Varejistas com anos de dados de transa√ß√µes, totalizando petabytes.        
- **Decis√µes comuns:**    
    - Uso de solu√ß√µes como **AWS Snowball ou Snowmobile** para transporte f√≠sico de grandes volumes.        
    - Ado√ß√£o de arquiteturas distribu√≠das como **Amazon EMR, S3, Redshift** para escalabilidade.        
#### 2. *Velocidade*
√â a **rapidez com que os dados s√£o gerados, coletados, processados e analisados**.
- **Impacto:** define se o processamento ser√° em **batch**, **quase em tempo real** ou **tempo real**.    
- **Exemplos:**    
    - Dados de sensores (IoT), atualizados a cada milissegundo.        
    - Sistemas de **trading de alta frequ√™ncia**, onde cada milissegundo conta.        
- **Decis√µes comuns:**    
    - Escolha entre ferramentas como **Kinesis Data Streams (tempo real)** vs **Kinesis Firehose (quase tempo real)**.        
    - Considera√ß√µes sobre **lat√™ncia**, **ordena√ß√£o de eventos**, e **consist√™ncia**.        
<div style="page-break-after: always;"></div>
#### 3. *Variedade*
Diz respeito aos **diferentes tipos e formatos de dados** com os quais voc√™ trabalha.
- **Tipos de dados:**    
    - **Estruturados**: Tabelas, bases relacionais (SQL).        
    - **Semiestruturados**: JSON, XML.        
    - **N√£o estruturados**: PDFs, v√≠deos, √°udios, imagens, e-mails.        
- **Exemplos:**    
    - Empresa que analisa dados estruturados (bancos), semiestruturados (JSONs) e n√£o estruturados (e-mails).        
    - Sistemas de sa√∫de que lidam com dispositivos m√©dicos, prontu√°rios e formul√°rios.        
- **Desafio:** Unificar diferentes fontes e formatos em um reposit√≥rio ou camada de an√°lise comum (ex: **Athena**, **Glue**, **Lake Formation**).    
### üìå Outros V's frequentemente citados
Embora o exame AWS enfatize os **3 V's principais**, outros V‚Äôs tamb√©m s√£o discutidos na literatura de Big Data:
- **Veracidade (4¬∫ V):** confian√ßa e qualidade dos dados (dado ruidoso, incompleto, inconsistente).    
- **Valor (5¬∫ V):** a utilidade que os dados proporcionam para tomada de decis√£o.    
- **Variabilidade:** flutua√ß√£o nos padr√µes de dados ao longo do tempo.    
- **Visualiza√ß√£o:** a capacidade de transformar dados complexos em insights visuais acess√≠veis.    
### ‚úÖ Dica para a prova AWS Data Engineer
Concentre-se em:
- **Volume ‚Üí** Decis√µes de armazenamento e movimenta√ß√£o.    
- **Velocidade ‚Üí** Escolha entre solu√ß√µes de streaming vs batch.    
- **Variedade ‚Üí** Ferramentas e estrat√©gias para dados heterog√™neos.
<div style="page-break-after: always;"></div>
# Datawarehouses vs Data Lakes vs Lakehouses
### üìä *Data Warehouse (DWH)*
- **Conceito**: Reposit√≥rio centralizado e estruturado, otimizado para an√°lises e consultas complexas.    
- **Formato de Dados**: Apenas dados **estruturados**.    
- **Processamento**: Utiliza o modelo **ETL** (Extra√ß√£o, Transforma√ß√£o e Carga).    
- **Schema**: **Schema on write** ‚Äì o esquema precisa estar definido antes da carga.    
- **Desempenho**: Alta performance em consultas anal√≠ticas.    
- **Casos de uso**: Business Intelligence, relat√≥rios corporativos, an√°lise de vendas, etc.    
- **Exemplo na AWS**: [Amazon Redshift](https://aws.amazon.com/redshift/)    

**Pontos de aten√ß√£o para o engenheiro de dados**:
- Planejar a modelagem de dados (ex: estrela, floco de neve).    
- Gerenciar mudan√ßas no schema com cuidado (pode ser custoso).    
- Otimizar consultas e √≠ndices.    
- Garantir integridade e qualidade dos dados durante o ETL.    
### üåä *Data Lake (DL)*
- **Conceito**: Reposit√≥rio de dados brutos no formato original.    
- **Formato de Dados**: Dados **estruturados, semiestruturados e n√£o estruturados**.    
- **Processamento**: Utiliza o modelo **ELT** (Extra√ß√£o, Carga e Transforma√ß√£o posterior).    
- **Schema**: **Schema on read** ‚Äì o esquema √© inferido na leitura.    
- **Flexibilidade**: Muito mais √°gil para ingest√£o de dados de diversas fontes.    
- **Casos de uso**: Ci√™ncia de dados, machine learning, descoberta de dados.    
- **Exemplo na AWS**: Amazon S3 + AWS Glue + Amazon Athena    

**Pontos de aten√ß√£o para o engenheiro de dados**:
- Garantir organiza√ß√£o via **parti√ß√µes**, **prefixos** e **nomenclatura padronizada**.    
- Tratar problemas de qualidade e padroniza√ß√£o de dados posteriormente.    
- Criar e manter o **cat√°logo de dados (ex: AWS Glue)**.    
- Cuidar do versionamento e controle de permiss√µes (ex: via Lake Formation).    
<div style="page-break-after: always;"></div>
### üè° *Data Lakehouse (DLH)*
- **Conceito**: Arquitetura h√≠brida que combina a flexibilidade do DL com a performance do DWH.    
- **Formato de Dados**: Suporta tanto dados estruturados quanto n√£o estruturados.    
- **Schema**: Suporte a **schema on write e on read**.    
- **Processamento**: Transa√ß√µes ACID, controle de versionamento e esquema evolutivo.    
- **Casos de uso**: BI + ML sobre o mesmo reposit√≥rio, unified analytics.    
- **Exemplo na AWS**: AWS Lake Formation + S3 + Redshift Spectrum  
    Outras tecnologias: Delta Lake (Databricks), Apache Hudi, Apache Iceberg.    

**Pontos de aten√ß√£o para o engenheiro de dados**:
- Definir formato de armazenamento (ex: Parquet, ORC).    
- Usar formatos transacionais (ex: Hudi, Delta, Iceberg) para time-travel, updates, deletes.    
- Cuidar da performance com particionamento e ordena√ß√£o de dados.    
- Monitorar metadados, compacta√ß√£o e versionamento.    
### üß† *Considera√ß√µes estrat√©gicas para o engenheiro de dados*
- **Escolha entre DWH, DL ou DLH** depende do tipo de dado, volume, variedade, velocidade e finalidade:    
    - DWH: BI e relat√≥rios sobre dados bem definidos.        
    - DL: Armazenamento flex√≠vel e barato com explora√ß√£o posterior.        
    - DLH: Plataforma unificada para an√°lises avan√ßadas e operacionais.        
- **Custo vs Performance**: DWH tende a ser mais caro, mas muito perform√°tico. DL √© mais barato, mas requer esfor√ßo na leitura. DLH busca o equil√≠brio.    
- **Governan√ßa de dados**: Implementar controle de acesso, versionamento e cataloga√ß√£o √© essencial em DL e DLH.    
- **Qualidade e observabilidade**: Ter pipelines de valida√ß√£o, alertas e monitoramento.    
- **Evolu√ß√£o do schema**: Principal desafio nos DLs; usar formatos como Iceberg ou Hudi ajuda bastante.
<div style="page-break-after: always;"></div>
# O que √© um Data Mesh
## üìå O que √© Data Mesh?
O **Data Mesh** (ou "malha de dados") √© uma **abordagem descentralizada** √† arquitetura e governan√ßa de dados, que prop√µe tratar os dados como **produtos** e distribui a responsabilidade pela governan√ßa e disponibiliza√ß√£o de dados para os **times de dom√≠nio** (_times de neg√≥cio_) que melhor conhecem esses dados (ex: vendas, financeiro, log√≠stica).

Diferente das arquiteturas tradicionais centralizadas, o Data Mesh **n√£o foca em tecnologia**, mas sim em **organiza√ß√£o e cultura**.

> Como diz o instrutor no material:  
> ‚ÄúTrata-se mais de governan√ßa e organiza√ß√£o do que de tecnologias reais.‚Äù
## üß± Pilares (Conceitos) do Data Mesh

|Pilar|Explica√ß√£o|
|---|---|
|**Dom√≠nio orientado a dados**|Cada equipe √© respons√°vel pelos dados do seu pr√≥prio dom√≠nio.|
|**Dados como produto**|Os dados devem ser mantidos como produtos utiliz√°veis por outros times.|
|**Plataforma de dados self-service**|Ferramentas e infraestrutura para permitir que os times publiquem e consumam dados sem depend√™ncias externas.|
|**Governan√ßa federada**|Cada dom√≠nio aplica regras locais, mas segue padr√µes centrais de seguran√ßa e interoperabilidade.|
## üõ†Ô∏è Import√¢ncia do Data Mesh na Engenharia de Dados

### ‚úÖ *Benef√≠cios*
- **Escalabilidade**: Evita que um √∫nico time de dados central vire gargalo.    
- **Autonomia**: Os dom√≠nios podem evoluir e publicar dados sem depend√™ncias.    
- **Contextualiza√ß√£o**: Quem entende os dados √© quem os disponibiliza.    
- **Governan√ßa e seguran√ßa distribu√≠das**: Mant√©m controle sem centralizar tudo.
### ‚ö†Ô∏è *Desafios*
- Requer **maturidade organizacional e cultural**.    
- Precisa de **plataforma robusta** (ex: AWS Lake Formation, Glue, S3).    
- A governan√ßa precisa ser **federada com padr√µes claros**.    
<div style="page-break-after: always;"></div>
## üîÅ Compara√ß√£o: Data Mesh vs Star Schema vs Snowflake Schema

| Caracter√≠stica                      | **Data Mesh**                                                           | **Star Schema**                                       | **Snowflake Schema**                                                 |
| ----------------------------------- | ----------------------------------------------------------------------- | ----------------------------------------------------- | -------------------------------------------------------------------- |
| **Modelo l√≥gico**                   | Descentralizado e orientado a dom√≠nios                                  | Centralizado, desnormalizado                          | Centralizado, normalizado                                            |
| **Modelo conceitual**               | Descentralizado e orientado a dom√≠nio                                   | Centralizado em um Data Warehouse                     | Centralizado com normaliza√ß√£o de dimens√µes                           |
| **Desenho de dados**                | Dados como produto, expostos por dom√≠nios com contratos de dados        | Tabela fato central com dimens√µes em volta            | Similar ao Star, mas dimens√µes s√£o normalizadas em m√∫ltiplas tabelas |
| **Foco**                            | Organiza√ß√£o, governan√ßa e autonomia dos dom√≠nios                        | Performance de leitura e simplicidade de modelagem    | Redu√ß√£o de redund√¢ncia e integridade dos dados                       |
| **Responsabilidade por dados**      | Times de neg√≥cio (dom√≠nios)                                             | Time central de engenharia de dados                   | Time central de engenharia de dados                                  |
| **Escalabilidade organizacional**   | Alta ‚Äì m√∫ltiplos dom√≠nios publicando dados                              | M√©dia ‚Äì depende do time de dados central              | M√©dia ‚Äì semelhante ao Star                                           |
| **Governan√ßa**                      | Federada com padr√µes centrais                                           | Centralizada                                          | Centralizada                                                         |
| **Infraestrutura t√≠pica**           | Data Lakes + Glue + Lake Formation + APIs                               | Data Warehouse (Ex: Redshift, BigQuery, Snowflake DW) | Data Warehouse com estrutura mais normalizada                        |
| **Tecnologia imposta**              | N√£o imp√µe tecnologia, √© um paradigma organizacional                     | Implica uso de DWHs                                   | Implica uso de DWHs com modelagem mais rigorosa                      |
| **Facilidade de manuten√ß√£o**        | Exige padr√µes e governan√ßa forte                                        | Simples de manter                                     | Mais complexa, mas com menor redund√¢ncia                             |
| **Facilidade de uso por analistas** | Alta (desde que bem documentado e com cat√°logo)                         | Alta (modelo intuitivo)                               | M√©dia (exige conhecimento da estrutura)                              |
| **Facilidade de consumo**           | Alta para usu√°rios com conhecimento de dom√≠nio; exige padr√£o de entrega | Alta ‚Äì modelo f√°cil de entender                       | M√©dia ‚Äì estrutura mais complexa, mas mais robusta                    |
Fonte: ChatGPT
<div style="page-break-after: always;"></div>

## üß¨ Semelhan√ßas e Conviv√™ncia
- **Complementares**: √â poss√≠vel ter um **modelo Star ou Snowflake dentro de um dom√≠nio do Data Mesh**.    
- **Todos exigem cat√°logos de dados e controle de acesso**, especialmente para uso em larga escala.    
- A **diferen√ßa central est√° na arquitetura organizacional**: enquanto Star e Snowflake focam na modelagem t√©cnica, o Data Mesh redefine quem possui os dados e como s√£o compartilhados.    
## üéØ Conclus√£o
O **Data Mesh** √© uma **resposta organizacional √† necessidade de escalar dados em grandes empresas**, permitindo que cada dom√≠nio seja respons√°vel pelos dados que conhece e controla.

> Como refor√ßa o material:  
> ‚Äú√â uma esp√©cie de mundo descentralizado em que os dados pertencem √†s equipes que mais sabem sobre eles.‚Äù

Comparado aos modelos **Star Schema** e **Snowflake**, o Data Mesh **n√£o busca substituir** esses modelos t√©cnicos, mas sim **reposicionar a responsabilidade** sobre os dados, alinhando arquitetura de dados com a estrutura organizacional.
# Gerenciando e Orquestrando Pipelines
## üîÑ O que √© um Pipeline de Dados?
Um **pipeline de dados** √© um conjunto de etapas organizadas para **movimentar, transformar e disponibilizar dados** de forma cont√≠nua ou em lote, desde a origem at√© o destino (como um Data Lake, Data Warehouse ou sistema de consumo anal√≠tico). Essas etapas geralmente incluem:
1. **Extra√ß√£o** de dados de fontes diversas;    
2. **Transforma√ß√£o** para adequa√ß√£o, limpeza, enriquecimento;    
3. **Carga** em destinos otimizados para an√°lise ou persist√™ncia.    
<div style="page-break-after: always;"></div>
## üîß ETL e ELT: Conceitos Fundamentais
O conte√∫do do arquivo fornecido detalha os dois principais padr√µes:
### üì¶ ETL (Extract, Transform, Load)
- **Extra√ß√£o**: captura dos dados brutos de fontes diversas ‚Äî bancos de dados, APIs, arquivos, etc.;    
- **Transforma√ß√£o**: limpeza, enriquecimento, deduplica√ß√£o e padroniza√ß√£o dos dados antes de serem carregados;    
- **Carga**: os dados j√° transformados s√£o armazenados no destino, geralmente um Data Warehouse.    

> **Usado quando**: o ambiente de destino (como Redshift ou Snowflake) √© mais r√≠gido e espera dados j√° organizados.
### üõ†Ô∏è ELT (Extract, Load, Transform)
- **Extra√ß√£o**: dados brutos s√£o capturados como no ETL;    
- **Carga**: os dados s√£o primeiramente armazenados em um Data Lake (como o S3);    
- **Transforma√ß√£o**: ocorre posteriormente, usando recursos computacionais do destino.    

> **Usado quando**: temos alta capacidade de processamento no destino (Athena, BigQuery, etc.) e dados s√£o carregados em estado bruto.
## üìå Carga e Transforma√ß√£o: Detalhamento T√©cnico
### üì• Extra√ß√£o
- Pode vir de:    
    - Bancos de dados relacionais (MySQL, PostgreSQL‚Ä¶);        
    - Sistemas como Salesforce, SAP;        
    - APIs REST ou arquivos CSV, logs, JSON;        
- Deve garantir:    
    - **Integridade dos dados** (n√£o perder ou duplicar);        
    - **Pol√≠tica de retries** (caso de falha em API);        
    - **Velocidade adequada** (streaming, near real-time ou batch).        
<div style="page-break-after: always;"></div>
### üîÑ Transforma√ß√£o
Inclui:
- **Limpeza**: remo√ß√£o de nulos, corre√ß√£o de erros;    
- **Enriquecimento**: jun√ß√µes com outras fontes;    
- **Convers√£o de tipos**: datas como string para `timestamp`, por exemplo;    
- **Padroniza√ß√£o de formatos**;    
- **C√°lculos**: agrega√ß√µes, m√©tricas, derivadas;    
- **Valida√ß√µes**: regras de qualidade, como colunas obrigat√≥rias.    

Transforma√ß√µes podem ser feitas em:
- Python com pandas;    
- PySpark em EMR;    
- SQL (no pr√≥prio destino, no modelo ELT);    
- Glue, DataBrew ou workflows via Airflow. 
### üì§ Carga
- Armazenamento no destino: S3, Redshift, Snowflake, BigQuery, etc.;    
- Pode ocorrer em **batch** (ex: uma vez por dia) ou **streaming** (ex: Kinesis, Kafka, DMS);    
- Requer:    
    - Monitoramento de falhas;        
    - Garantia de consist√™ncia;        
    - Gerenciamento de parti√ß√µes, formatos (Parquet, Avro, etc.).        
## ‚öôÔ∏è Orquestra√ß√£o do Pipeline
Pipelines devem ser **automatizados e monitorados**. Ferramentas da AWS incluem:
- **AWS Glue**: ETL serverless, com workflows visuais;    
- **Step Functions**: orquestra execu√ß√£o passo a passo;    
- **Lambda + EventBridge**: pipelines reativos a eventos;    
- **MWAA (Apache Airflow gerenciado)**: para pipelines complexos e depend√™ncias entre tarefas.    
## üß† Conclus√£o
Um *pipeline de dados bem projetado* √© fundamental para sistemas anal√≠ticos modernos. Entender quando aplicar ETL ou ELT depende do contexto t√©cnico, tipo de dados, volume, frequ√™ncia e destino. Dominar essas pr√°ticas √© essencial para engenheiros de dados que lidam com dados em escala na nuvem.
<div style="page-break-after: always;"></div>

# Fontes de Dados e Formato de Dados Comuns
## üì• Fontes de Dados Comuns
### 1. *JDBC (Java Database Connectivity)*
- Interface para conectar com bancos relacionais.    
- **Pr√≥:** Independente de plataforma.    
- **Contra:** Requer uso de Java.
### 2. *ODBC (Open Database Connectivity)*
- Interface gen√©rica e independente de linguagem.    
- **Pr√≥:** Compat√≠vel com diversas linguagens.    
- **Contra:** Dependente de drivers da plataforma.    
### 3. *APIs (REST/SOAP)*
- Interface comum para sistemas modernos.    
- **Usado quando:** O acesso a dados √© feito via HTTP.    
### 4. *Arquivos de Log Brutos*
- Armazenados em S3 ou HDFS.    
- Frequentemente n√£o estruturados.    
### 5. *Streams em Tempo Real*
- Exemplos: **Kafka**, **Kinesis**, **Flink**.    
- Dados chegam em tempo real e requerem sistemas capazes de consumir, processar e armazenar.    
## üìÇ Formatos de Dados Comuns
### 1. *CSV (Comma-Separated Values)*
- **Formato:** Texto, leg√≠vel por humanos.    
- **Pr√≥s:** Simples, compat√≠vel com quase tudo, √≥timo para exporta√ß√µes e importa√ß√µes.    
- **Contras:** N√£o √© eficiente para grandes volumes; dif√≠cil lidar com estruturas aninhadas.    
### 2. *JSON (JavaScript Object Notation)*
- **Formato:** Texto, leg√≠vel por humanos, baseado em pares chave-valor.    
- **Pr√≥s:** Suporta estruturas aninhadas e esquema flex√≠vel.    
- **Contras:** Menos eficiente que formatos bin√°rios.    
<div style="page-break-after: always;"></div>
### 3. *Avro*
- **Formato:** Bin√°rio com schema embutido.    
- **Pr√≥s:** Eficiente, ideal para streaming e serializa√ß√£o de dados.    
- **Contras:** N√£o leg√≠vel por humanos.    
### 4. *Parquet*
- **Formato:** Colunar e bin√°rio.    
- **Pr√≥s:** Otimizado para leitura seletiva de colunas, compress√£o eficiente.    
- **Ideal para:** Big data analytics em Spark, Hive, Athena, Redshift Spectrum.    
- **Contras:** N√£o √© leg√≠vel por humanos; pouco eficiente se voc√™ sempre acessa o registro completo. 
## ‚úÖ Outros formatos a considerar:
- ### *ORC (Optimized Row Columnar):*    
    - Similar ao Parquet, mas mais comum em ambientes Hive.        
- ### *XML:*    
    - Ainda usado em integra√ß√µes legadas, mas com overhead maior.        
- ### *Delta Lake e Iceberg:*    
    - Formatos open table que adicionam controle transacional sobre arquivos Parquet.        
- ### Integra√ß√£o com Servi√ßos AWS:
	- **Athena**: L√™ diretamente CSV, JSON, Parquet, ORC.    
	- **Glue**: Converte e cataloga dados em qualquer formato.    
	- **Redshift Spectrum**: Ideal para leitura de Parquet e ORC no S3.
## ‚úÖ Boas pr√°ticas:
- **Compacta√ß√£o:** Use gzip, snappy ou zstd com Parquet/Avro.    
- **Schema evolution:** JSON e Avro s√£o mais flex√≠veis.    
- **Particionamento:** Essencial para desempenho em leitura no S3 (Athena, EMR).
<div style="page-break-after: always;"></div>
# Modelagem de Dados, Linhagem de Dados e Evolu√ß√£o de Modelos (Schema Evolution)
## üìò Modelagem de Dados (Data Modeling)
### *Pontos abordados no material:*
- Explica√ß√£o do **modelo dimensional (esquema em estrela)**:    
    - **Fato**: tabela central com m√©tricas quantitativas (ex: compras).        
    - **Dimens√µes**: tabelas com atributos descritivos (ex: aluno, curso, pagamento).        
    - Uso de **chaves prim√°rias e estrangeiras** para vincular as tabelas.        
    - Representado por **Diagramas Entidade-Relacionamento (ERD)**.       
### *Lacunas e complementos importantes:*
- **Modelo Snowflake**:    
    - Variante do esquema estrela, com dimens√µes **normalizadas**.        
    - Ajuda a economizar espa√ßo, mas pode dificultar a performance de leitura.        
- **Modelo Relacional vs Dimensional**:    
    - Relacional: usado para OLTP (transacional).        
    - Dimensional: usado para OLAP (anal√≠tico).        
- **Modelagem NoSQL**:    
    - Em bancos de documentos (MongoDB, DynamoDB), a modelagem segue o padr√£o de **desnormaliza√ß√£o** para performance.        
    - Conceitos como **modelagem orientada a consultas** s√£o comuns.        
- **Boas pr√°ticas**:    
    - Identificar **entidades e relacionamentos**.        
    - Definir **chaves prim√°rias naturais ou substitutas**.        
    - **Evitar redund√¢ncias** e **anomalias de atualiza√ß√£o**.        
## üîÅ Linhagem de Dados (Data Lineage)
### *Pontos abordados no material:*
- Representa√ß√£o visual do **fluxo dos dados**, da origem at√© o destino.    
- Import√¢ncia para:    
    - **Depura√ß√£o de erros**.        
    - **Auditoria e compliance**.        
    - **Documenta√ß√£o e onboarding**.        
- Exemplo usando:    
    - **Spline Agent** + **Apache Spark** + **AWS Glue**.        
    - Armazenamento de linhagem no **Amazon Neptune (grafo)**.        
<div style="page-break-after: always;"></div>
### *Lacunas e complementos importantes:*
- **Tipos de linhagem**:    
    - **Linhagem de dados t√©cnica**: descreve jobs, tabelas, scripts, colunas e tipos.        
    - **Linhagem de dados empresarial**: associada a regras de neg√≥cios e processos.        
- **Ferramentas populares**:    
    - **OpenLineage**, **Amundsen**, **DataHub**, **Collibra**, **Alation**.        
    - AWS: **AWS Glue Data Catalog**, **SageMaker Lineage**, **Lake Formation**.        
- **Formato de armazenamento da linhagem**:    
    - Geralmente representado como **grafos direcionados ac√≠clicos (DAGs)**.        
- **Integra√ß√£o com orquestradores**:    
    - Airflow pode capturar metadados e gerar linhagem com plug-ins (ex: OpenLineage).        
## üß¨ Evolu√ß√£o de Esquemas (Schema Evolution)
### *Pontos abordados no material:*
- Capacidade de modificar o esquema **sem quebrar pipelines ou sistemas legados**.    
- Suporte a:    
    - **Adi√ß√£o de colunas**.        
    - **Remo√ß√£o de colunas**.        
    - **Modifica√ß√£o de tipos de dados** (com cautela).        
- Exemplo: **AWS Glue Schema Registry** para registrar e validar esquemas.    
### *Lacunas e complementos importantes:*
- **Compatibilidade de esquema**:    
    - **Forward compatibility**: novos produtores, leitores antigos.        
    - **Backward compatibility**: produtores antigos, leitores novos.        
    - **Full compatibility**: suporta ambos.        
- **Formatos de dados com suporte nativo √† evolu√ß√£o**:    
    - **Avro** (com registro de esquema).        
    - **Parquet** (metadados embutidos, mas menos flex√≠vel).        
    - **ORC** e formatos transacionais como:        
        - **Apache Hudi**, **Apache Iceberg**, **Delta Lake** (controle de vers√£o + schema evolution).            
- **Exemplos de desafios**:    
    - Altera√ß√µes de tipo n√£o compat√≠veis (e.g., `int` ‚Üí `string`).        
    - Ordem de campos em Avro pode importar se o leitor n√£o for tolerante.        
- **Verifica√ß√£o e valida√ß√£o**:    
    - Glue permite configurar **modo de compatibilidade**.        
    - Integra√ß√µes com **Kafka + Schema Registry (Confluent ou AWS)**.        
<div style="page-break-after: always;"></div>
## üß† Dicas para a prova
- **Aten√ß√£o a perguntas de compatibilidade de esquemas**.    
- Entender **diferen√ßas entre modelagem OLTP x OLAP**.    
- Reconhecer cen√°rios pr√°ticos com ferramentas AWS (Glue, Neptune, S3).    
- Saber distinguir entre **linhagem t√©cnica e de neg√≥cios**.    
- Interpretar **impactos de mudan√ßas de esquema** em pipelines ETL.
# Otimiza√ß√£o de performance de Bancos de dados
### 1. **Indexa√ß√£o**
- Evita varreduras completas de tabela (full scan).    
- Permite acesso mais r√°pido aos dados.    
- Ajuda a refor√ßar **unicidade** e **integridade** dos dados (√≠ndices √∫nicos).    
- Fundamental analisar as **consultas** frequentes para definir quais colunas devem ser indexadas.    
- √çndices compostos (multi-coluna) podem ser √∫teis para filtros combinados.    
### 2. **Particionamento**
- Reduz a quantidade de dados lidos ao dividir grandes volumes com base em colunas estrat√©gicas (ex: data, regi√£o).    
- Permite:    
    - **Filtragem eficiente** (ex: parti√ß√£o por m√™s).        
    - **Processamento paralelo** (cada parti√ß√£o processada isoladamente).        
    - **Gerenciamento de ciclo de vida** (parti√ß√µes antigas movidas ou exclu√≠das).        
- Particionamento por intervalo, lista, hash ou h√≠brido.    
### 3. **Compacta√ß√£o**
- Reduz custo de armazenamento e acelera leitura de disco.    
- Mitiga gargalos de **I/O** de disco.    
- Formatos comuns: **GZIP**, **LZOP**, **BZIP2**, **Zstandard**.    
- Deve-se balancear entre:    
    - **Taxa de compress√£o** (quanto reduz).        
    - **Tempo de descompress√£o** (carga de CPU).        
<div style="page-break-after: always;"></div>
### 4. **Compacta√ß√£o Colunar**
- Muito eficiente com dados armazenados em formato colunar (ex: **Parquet**, **ORC**).    
- Vantagem:    
    - Dados homog√™neos por coluna facilitam a compress√£o.        
    - Ideal para workloads de leitura anal√≠tica, como em data lakes e data warehouses.        
###  **Complementos Relevantes para a Prova**
#### üîπ _Query Optimization_
- Use planos de execu√ß√£o (EXPLAIN) para analisar gargalos.    
- Evite `SELECT *` ‚Äî sempre especifique as colunas necess√°rias.    
- Prefira filtros com colunas indexadas ou particionadas.    
#### üîπ _Normaliza√ß√£o vs Desnormaliza√ß√£o_
- **Normaliza√ß√£o** melhora integridade e evita redund√¢ncia.    
- **Desnormaliza√ß√£o** pode melhorar performance de leitura, importante em OLAP.    
#### üîπ _Materialized Views_
- Armazenam o resultado de queries complexas.    
- Podem ser atualizadas periodicamente (√∫til para relat√≥rios pesados).    
#### üîπ _Cache e Buffer Pool_
- Alguns SGBDs fazem cache em mem√≥ria de dados lidos com frequ√™ncia (ex: PostgreSQL, Oracle).    
- Dimensionar corretamente a mem√≥ria alocada ao buffer/cache impacta diretamente na performance.    
#### üîπ _Tuning de Par√¢metros_
- Par√¢metros como n√∫mero de conex√µes simult√¢neas, buffers, cache de disco e paralelismo influenciam no desempenho global do banco.
<div style="page-break-after: always;"></div>
# T√©cnicas de Amostragem de dados
## üéØ Objetivo da Amostragem
Reduzir o volume de dados a ser processado **mantendo a representatividade** para an√°lise. Ideal quando:
- Se quer testar hip√≥teses rapidamente;    
- Reduzir custos computacionais;    
- Trabalhar com subconjuntos representativos de dados muito grandes.    
## üìä *Principais T√©cnicas Apresentadas*
### 1. *Amostragem Aleat√≥ria Simples*
- Cada item tem **chance igual de ser selecionado**.    
- √ötil quando **n√£o h√° categorias distintas** nos dados.    
- N√£o garante equil√≠brio entre subgrupos.    
### 2. *Amostragem Estratificada*
- Dados s√£o divididos em **estratos** (subgrupos homog√™neos).    
- √â feita uma **amostragem aleat√≥ria dentro de cada estrato**.    
- Garante que todos os subgrupos estejam **representados adequadamente**.    
- Exemplo: selecionar 2 exemplos de cada categoria (livros, m√∫sicas, roupas etc.), mesmo que desproporcional √† popula√ß√£o total.    
### 3. *Amostragem Sist√™mica*
- Sele√ß√£o com base em um **intervalo fixo**: ex. "um a cada tr√™s".    
- Simples de implementar, mas pode induzir **vi√©s** se houver padr√£o peri√≥dico nos dados.    
### 4. *Outras t√©cnicas citadas:
- **Amostragem por agrupamento (cluster sampling):** divide a popula√ß√£o em grupos e sorteia grupos inteiros.    
- **Amostragem por conveni√™ncia:** baseada na **facilidade de acesso** aos dados.    
- **Amostragem por julgamento (ou intencional):** baseada no **conhecimento pr√©vio** do analista sobre o que deve ser inclu√≠do.    
<div style="page-break-after: always;"></div>
## üß† *Conceitos Complementares Relevantes para Certifica√ß√£o*
### üüß T√©cnicas Adicionais:
- **Bootstrap Sampling (reamostragem com reposi√ß√£o):** usada para estimativas estat√≠sticas robustas;    
- **Reservoir Sampling:** √∫til para amostragem de **fluxos de dados (streams)** com tamanho indeterminado.   
### üü® Cuidados ao realizar amostragem:
- Verificar **vi√©s de sele√ß√£o**;    
- Avaliar **vari√¢ncia e representatividade**;    
- Considerar a **distribui√ß√£o dos dados originais**.    
### üü© Aplica√ß√µes pr√°ticas em Engenharia de Dados:
- Redu√ß√£o de volume para testes de pipelines;    
- Cria√ß√£o de datasets balanceados para ML;    
- Preven√ß√£o de overfitting por subamostragem;    
- Valida√ß√£o de dados com consist√™ncia entre amostras e popula√ß√£o.
# Mecanismos de distor√ß√£o de dados (Data Skew)
## ‚úÖ *Defini√ß√£o*
Data Skew ocorre quando h√° **distribui√ß√£o desigual de dados entre parti√ß√µes** em sistemas distribu√≠dos. Isso afeta negativamente o desempenho de pipelines de processamento distribu√≠do como Spark, Hadoop ou sistemas de banco de dados particionados.
## ‚öôÔ∏è *Causas Comuns*
1. **Distribui√ß√£o desigual de chaves**:    
    - Ex: alguns valores de chave (como o ID de Brad Pitt em um banco de filmes) recebem muito mais acessos.        
2. **Problema da celebridade**:    
    - Um pequeno grupo de valores (celebridades) concentra grande volume de dados/tr√°fego, gerando sobrecarga em parti√ß√µes espec√≠ficas.        
3. **Particionamento inadequado**:    
    - Estrat√©gias de particionamento gen√©ricas (como hash de ID) n√£o refletem a realidade dos dados.        
4. **Distor√ß√£o temporal**:    
    - Ex: parti√ß√µes por ano podem gerar parti√ß√µes de tamanhos muito diferentes (anos recentes com muito mais dados).        
<div style="page-break-after: always;"></div>
## üìâ *Impactos*
- Subutiliza√ß√£o de n√≥s em um cluster distribu√≠do.    
- Atrasos no processamento por sobrecarga em poucas parti√ß√µes.    
- Custo elevado de computa√ß√£o com baixa performance.    
- Problemas em joins com chaves desbalanceadas.    
## üõ†Ô∏è *T√©cnicas de Mitiga√ß√£o*
1. **Particionamento Adaptativo**:    
    - Reajusta parti√ß√µes dinamicamente com base na distribui√ß√£o observada.        
2. **Salting**:    
    - Adiciona valor aleat√≥rio √† chave de parti√ß√£o para melhorar a distribui√ß√£o (ex: transformar `id` em `id_random_salt`).        
3. **Reparticionamento peri√≥dico**:    
    - Reprocessa os dados com nova l√≥gica de particionamento.        
    - Pode ser disruptivo e custoso.        
4. **Amostragem de dados**:    
    - Amostras s√£o usadas para entender a distribui√ß√£o real dos dados antes do processamento completo.        
5. **Particionamento personalizado**:    
    - Define regras espec√≠ficas baseadas no conhecimento do dom√≠nio (ex: colocar celebridades em parti√ß√µes separadas).        
## üìà *Monitoramento e Preven√ß√£o*
- Use ferramentas como **AWS CloudWatch** para criar **alarmes sobre m√©tricas de distor√ß√£o**, como:    
    - Tempo de execu√ß√£o de etapas.        
    - Volume de dados por parti√ß√£o.        
    - Tamanho de arquivos em parti√ß√µes.        
<div style="page-break-after: always;"></div>
## üß† *Complementos Importantes para a Certifica√ß√£o*
Embora o material original seja abrangente, alguns pontos extras √∫teis incluem:

|Conceito|Detalhe|
|---|---|
|**Skew em joins**|Quando uma chave de join √© muito frequente, o n√≥ que processa essa chave pode ficar sobrecarregado. T√©cnicas como **broadcast join** ou **salting + explode** podem ser usadas.|
|**Uso de `salting` com Spark**|Pode-se usar `withColumn("key_salted", concat(col("key"), lit("_"), rand()))` antes de um join.|
|**Shuffle Skew**|Distor√ß√£o durante a movimenta√ß√£o de dados entre n√≥s. Indica necessidade de reavaliar chave de parti√ß√£o.|
|**Ferramentas de diagn√≥stico**|Spark UI, logs de execu√ß√£o e m√©tricas de jobs ajudam a identificar gargalos causados por skew.|
|**Split de arquivos**|Arquivos muito grandes ou muito pequenos tamb√©m podem causar skew se mal balanceados no HDFS/S3.|

# Perfil e Valida√ß√£o de Dados
## 1. *Defini√ß√£o Geral*
Perfil de dados e valida√ß√£o dizem respeito √† **qualidade dos dados** e sua **adequa√ß√£o ao uso**, garantindo que os dados sejam confi√°veis, completos, consistentes e precisos para an√°lises e tomadas de decis√£o.
## üß™ *Dimens√µes da Valida√ß√£o de Dados*
### üìå **1. Integridade de Dados**
- Refere-se √† presen√ßa de dados esperados:    
    - Verifica√ß√£o de **dados faltantes (nulls)**.        
    - C√°lculo da **percentual de campos ausentes** por coluna.        
    - Exemplo: valores salariais ausentes afetam m√©dias calculadas.        
üîß **A√ß√µes recomendadas:**
- **Remo√ß√£o** de registros incompletos.    
- **Imputa√ß√£o** com valores padr√£o, m√©dia ou mediana.    
- Avaliar se o **dado ausente √© cr√≠tico ou toler√°vel**.    
<div style="page-break-after: always;"></div>
### üìå **2. Consist√™ncia de Dados**
- Dados devem manter **formato e representa√ß√£o uniformes** entre diferentes tabelas/fontes.    
- Exemplo cl√°ssico:    
    - Escalas de avalia√ß√£o de filmes: 1 a 5 vs. 1 a 10.        
    - Unidades de medida diferentes (ex: "kg" vs. "g").        
üîß **A√ß√µes recomendadas:**
- **Padroniza√ß√£o de formatos e unidades** antes de combinar dados.    
- **Valida√ß√£o cruzada** entre campos relacionados (ex: tipo de dado, range, categoria).    
### üìå **3. Precis√£o dos Dados**
- Verifica se os dados s√£o **corretos e confi√°veis**.    
- Dif√≠cil de validar sem uma **fonte de verdade (golden source)**.    
üîß **A√ß√µes recomendadas:**
- **Checks de sanidade** (valores dentro de faixas aceit√°veis).    
- **Verifica√ß√µes estat√≠sticas** de distribui√ß√µes esperadas.    
- Uso de **modelos de detec√ß√£o de outliers/anomalias**.    
#### üìå **4. Validade / Integridade Referencial**
- Avalia se os dados **mant√™m rela√ß√µes entre si ao longo do tempo**.    
- Foco em:    
    - **Chaves prim√°rias e estrangeiras**.        
    - Relacionamentos entre tabelas (**joins consistentes**).        
    - **Atualiza√ß√µes que quebram depend√™ncias**.        
üîß **A√ß√µes recomendadas:**
- **Verifica√ß√£o peri√≥dica de integridade referencial**.    
- Garantia de **cascata de atualiza√ß√µes e dele√ß√µes**.    
- Ferramentas de **data lineage** para rastrear depend√™ncias.    
## ‚ûï *Complementos Relevantes para Certifica√ß√£o*
### üìä **Perfil de Dados (Data Profiling)**
- Processo de an√°lise de dados brutos para entender sua **estrutura, qualidade e conte√∫do**.    
- M√©tricas comuns:    
    - **Cardinalidade** (n¬∫ de valores distintos por campo).        
    - **Frequ√™ncia de valores**.        
    - **Distribui√ß√£o estat√≠stica**.        
    - **An√°lise de padr√µes (regex, formatos esperados)**.        
üõ†Ô∏è **Ferramentas √∫teis**:
- AWS Glue DataBrew, Great Expectations, Deequ, Pandera, PyDeequ.    
<div style="page-break-after: always;"></div>
### üß† **Boas Pr√°ticas**
- Automatizar valida√ß√µes com pipelines de dados (ETL/ELT).    
- Integrar verifica√ß√µes de qualidade com alertas e dashboards.    
- Implementar **testes unit√°rios e de integra√ß√£o** para dados.    
- Manter **versionamento de esquema e contratos de dados (Data Contracts)**.    
## üìå Conclus√£o
A valida√ß√£o e o perfilamento de dados s√£o **fundamentais para garantir a confiabilidade e o valor anal√≠tico** em um pipeline de engenharia de dados. Em contextos de certifica√ß√£o, espere perguntas sobre:
- Identifica√ß√£o de problemas comuns de qualidade.    
- Estrat√©gias para valida√ß√£o e profilamento.    
- Impacto da m√° qualidade nos resultados anal√≠ticos.
# Revis√£o de SQL
## Agrega√ß√£o, Agrupamento, Ordena√ß√£o e Pivoteamento
## Tipos de Jun√ß√£o (Join Types)
## Express√µes Regulares
# Versionamento (GIT)
## üìå *Conceitos Fundamentais*
- Git √© um **sistema de controle de vers√£o distribu√≠do**.    
- Utiliza **reposit√≥rios locais e remotos** (ex: GitHub).    
- Permite **trabalho colaborativo simult√¢neo**, sem conflitos frequentes.    
- Suporte a **ramifica√ß√µes (branches)** para desenvolvimento de features, corre√ß√µes e testes.    
## üìå *Fluxo de Trabalho B√°sico*
1. `git clone`: Clona um reposit√≥rio remoto.    
2. `git add`: Adiciona mudan√ßas para a √°rea de staging.    
3. `git commit -m`: Salva as altera√ß√µes localmente com uma mensagem.    
4. `git push`: Envia as altera√ß√µes ao reposit√≥rio remoto.    
5. `git pull`: Atualiza a branch local com altera√ß√µes do remoto.    
6. `git branch`, `git checkout -b`, `git merge`: Cria√ß√£o, navega√ß√£o e integra√ß√£o de branches.    
## üìå *Configura√ß√£o e Inicializa√ß√£o*
- `git init`: Cria um novo reposit√≥rio local.    
- `git config`: Configura nome de usu√°rio e e-mail.    
## üìå *Diagn√≥stico e Hist√≥rico*
- `git status`: Mostra estado dos arquivos.    
- `git log`: Hist√≥rico de commits.    
- `git diff`: Diferen√ßa entre vers√µes.    
- `git blame`: Identifica quem alterou o qu√™.    
### üìå *Gerenciamento de Branches*
- `git branch`: Lista branches locais.    
- `git branch -d`: Deleta branch local.    
- `git checkout`: Muda de branch.    
- `git checkout -b`: Cria e muda para nova branch.    
- `git merge`: Mescla uma branch √† branch atual.    
- `git rebase`: Reaplica commits de uma branch sobre outra.    
- `git cherry-pick`: Aplica commit espec√≠fico a outra branch.    
## üìå *Comandos Avan√ßados*
- `git stash`, `git stash pop`: Armazenamento tempor√°rio de altera√ß√µes n√£o commitadas.    
- `git reset [--hard]`: Redefine staging ou diret√≥rio de trabalho.    
- `git revert`: Desfaz altera√ß√µes de um commit anterior.    
- `git fetch`: Busca altera√ß√µes do remoto sem aplicar (diferente do pull).    
- `git remote add/list`: Adiciona e lista reposit√≥rios remotos.    
## üìå *Manuten√ß√£o e Recupera√ß√£o*
- `git fsck`: Verifica integridade do reposit√≥rio.    
- `git gc`: Limpeza e otimiza√ß√£o (garbage collection).    
- `git reflog`: Hist√≥rico de atualiza√ß√µes das refer√™ncias (√∫til para recuperar commits perdidos).    
## üß† *Pontos Relevantes que Poderiam Ser Complementados para a Certifica√ß√£o*
Apesar do documento ser bastante abrangente, **alguns conceitos √∫teis para certifica√ß√£o n√£o foram cobertos**, como:
### üìÅ **.gitignore**
- Arquivo que lista padr√µes de arquivos e pastas a serem ignorados pelo Git.    
- Exemplo pr√°tico: `*.log`, `venv/`, `__pycache__/`.    
### üîÑ **Workflows de Git**
- **Git Flow**, **Feature Branch Workflow**, **Trunk-based development**.    
- Importante para equipes de engenharia de dados em ambientes colaborativos.    
### üîê **Controle de Acesso e Seguran√ßa**
- Chaves SSH vs autentica√ß√£o com token pessoal (PAT).    
- Importante ao trabalhar com reposit√≥rios privados.    
### üîÑ **CI/CD Integrado**
- Git com **pipelines de integra√ß√£o cont√≠nua** (GitHub Actions, GitLab CI).    
- Ajuda a automatizar testes, deploy de ETLs e versionamento de DAGs (Airflow, por exemplo).    
### üì¶ **Versionamento de Dados**
- Embora o Git versiona **c√≥digo**, para dados pode-se usar:    
    - [DVC (Data Version Control)](https://dvc.org/)        
    - LakeFS, Delta Lake, Apache Hudi (com suporte a controle de vers√µes de dados)        
### üîÑ **Tagging e Releases**
- `git tag`: Marca vers√µes espec√≠ficas (√∫til para deploys).    
- `git describe`: Mostra a vers√£o associada ao √∫ltimo tag.
## üéØ *O Que Saber Para a Certifica√ß√£o de Engenharia de Dados*
1. **Comandos essenciais do Git** (clone, pull, push, branch, merge, etc.).    
2. **Uso de branches** para colabora√ß√£o segura.    
3. **Fluxo b√°sico de staging ‚Üí commit ‚Üí push**.    
4. **Hist√≥rico e revers√µes de mudan√ßas**.    
5. **Boa pr√°tica com `.gitignore` e tags**.    
6. **Como reposit√≥rios locais/remotos interagem**.    
7. **Como o versionamento colabora com dados e pipelines (Git + CI/CD + DVC/LakeFS)**.
